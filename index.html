<!DOCTYPE html>
<html>
<head> 
<link rel = "stylesheet" href="index_style.css">
<link rel = "stylesheet" href="images">
<link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
</head>
<body>

<p class="titulo">Computação visual</p>
<br><br>
<p class="subtitulo">Aula 1:</p>
<p class="subtitulo">O que eu achava que era:</p>

<p>
1. Programar GUIs, UX (User experience) e design de sites e softwares em geral.<br>
2. Modelação 3D e 2D. 
</p>

<br><br>

<p class="subtitulo">Exemplos de sub-área</p>

<p class="subsubtitulo">Computação Gráfica </p>
<p> 
Exemplo: Shading utilizando OpenGL<br>
Site: https://learnopengl.com/Getting-started/Shaders<br>
Descrição: É um tutorial sobre como funciona o OpenGL, ele inclui exemplos, explicação, código
fonte para auxiliar, exercícios com resposta e a documentação é bem escrita.<br>
Motivo: Realmente é bem feito esse tutorial, e como é feito em C++ eu também tenho familiaridade,
além de ser bem simples.
</p>


<p class="subsubtitulo">Visão Computacional</p>
<p>
Exemplo: Detecção de digital utilizando Edge Detection<br>
Site: https://chooch.ai/computer-vision/what-are-the-applications-of-edge-detection/#:~:text=Applying%20edge%20detection%20makes%20it,cases%3A%20self%2Ddriving%20cars.<br>
Site2: https://d1wqtxts1xzle7.cloudfront.net/68544602/0031-3203_2887_2990078-120210803-2319-15ky6jc.pdf?1627992344=&response-content-disposition=inline%3B+filename%3DEdge_Detection_in_fingerprints.pdf&Expires=1645033301&Signature=I5uaw~tdtV5X~W4fs96CH8DEqy7OJaZQEJPk-mGBc4~QDiNmbOBaU0W5hDnYnknEr9vAYu3xhHQszNWsqF7IWirdRvRSJqBmmYE1SEiQi0xpzagNJgpca0G-oplXCC4EfUuG-FcI6rh2~ICkcN57mX5whYRDYSgzel36w3WySNkz6EjKULGqhl3CZUgk8JzlMUDbAndjX~ifw-wzVkh5GNdta6Ry7MYN9ZVRPVy2Rw-CbrsNg8hkDav~eS40v4Aq1hZ9Ry1gpIc2qoRbDNlYUEkves4jJLQkhOvWB5NwHsdFLYHEQO91caJxVmSvRWaltWZ-ZwJS9eM6dO3nDH62dA__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA<br><br>
Descrição: Utilizando Edge detection para verificar o contorno da digital em contraste com o fundo, e diminuir o ruído causado.<br>
Motivo: É uma tecnologia usada atualmente em vários sistemas, como bancos para verificar a autenticidade da pessoa.<br>
</p>

<p class="subsubtitulo">Processamento de Imagens</p> 
<p>
Exemplo: Transmissão e codificação de imagens.<br>
Site: https://www.tutorialspoint.com/dip/applications_and_usage.htm<br>
Descrição: Codificação e transmissão de imagens e vídeos, com mais rapidez e melhoria nas imagens, permitindo até transmissão ao vivo (LIVE) <br>
Motivo:Parecia interessante, também é utilizado bastante hoje em dia, principalmente por conta da pandemia. 
</p>


<br><br><br><br>
<p class = "subtitulo">Aula 2 </p>
<br>
<p> Problema: Identificação Automática de placas de veículo</p><br>
<p> Solução: Utilizando Python, OpenCV, biblioteca pytesseract e Raspberry PI para detectar as letras da placa</p>
<p>Como o filtro ajudou: Foi utilizado o Blur gaussaniano para melhorar a imagem</p>
<p> site/ papel: https://professor.luzerna.ifc.edu.br/ricardo-antonello/wp-content/uploads/sites/8/2016/04/IDENTIFICA%c3%87%c3%83O-AUTOM%c3%81TICA-DE-PLACA-DE-VE%c3%8dCULOS-ATRAV%c3%89S-DE-PROCESSAMENTO-DE-IMAGEM-E-VIS%c3%83O-COMPUTACIONAL-.pdf</p>
<p> Importante: No papel se encontra, o código usado e exemplos utilizando placas</p>
<img src = "tela_placa_carro.png" >
<p>Imagem pega de https://professor.luzerna.ifc.edu.br/ricardo-antonello/wp-content/uploads/sites/8/2016/04/IDENTIFICA%c3%87%c3%83O-AUTOM%c3%81TICA-DE-PLACA-DE-VE%c3%8dCULOS-ATRAV%c3%89S-DE-PROCESSAMENTO-DE-IMAGEM-E-VIS%c3%83O-COMPUTACIONAL-.pdf</p>
<br><br><br><br>

<p class = "subtitulo">Aula 6, eu acho </p>
<p>Com base no material disponível no Moodle (slides sobre “Transformações de Intensidade e Filtragem Espacial”, em particular, os tópico de transformação de intensidade e de processamento de histograma – slides 13 a 57) e referências adicionais, faça uma pesquisa sobre como é possível: </p>

<p>1.Realizar a limiarização de uma imagem usando Python e scikit-image.</p>
<p>2.Plotar o histograma de uma imagem tons de cinza usando Python, scikit-image e matplotlib.</p>
<p>3.Plotar o histograma de uma imagem colorida (um histograma por canal de cor) usando Python, scikit-image e matplotlib.</p>
<p>4.Equalizar o histograma de uma imagem usando Python e scikit-image.</p>
<p>5.Detectar (concluir) que uma foto está subexposta ou que está superexposta, analisando o histograma.</p>
<p>6.Detectar (concluir) se uma imagem está com baixo contraste ou alto contraste, analisando o histograma.</p>
<p>Para cada item acima, inclua um código que exemplifica cada tarefa e uma imagem resultante do código (por exemplo, no item 2, a imagem deve conter a imagem em tons de cinza e o histograma da imagem).</p>

<p>Inclua as referências usadas na pesquisa.</p>
<p> referências:</p>
<a href='https://images.aws.nestle.recipes/resized/40b25559b85b265e885f55ec7c1e4d04_torta-lim%C3%A3o-receitas-nestle_1200_600.jpg'>Imagem</a><br>
<a href='https://www.kaggle.com/code/sanikamal/image-processing-with-scikit-image/notebook'>https://www.kaggle.com/code/sanikamal/image-processing-with-scikit-image/notebook</a><br>
<a href='https://scikit-image.org/docs/stable/auto_examples/color_exposure/plot_local_equalize.html'>https://scikit-image.org/docs/stable/auto_examples/color_exposure/plot_local_equalize.html</a><br>
<a href='https://acervolima.com/segmentacao-de-imagens-usando-o-modulo-scikit-image-do-python/'>https://acervolima.com/segmentacao-de-imagens-usando-o-modulo-scikit-image-do-python/</a><br>
<a href='https://www.tecmundo.com.br/internet/8616-fotografia-como-funcionam-os-histogramas.htm'>https://www.tecmundo.com.br/internet/8616-fotografia-como-funcionam-os-histogramas.htm</a><br>
<br><br>
<img src= "images/foto.jpg"><br>
<p>Foto original</p>

<p>código para foto cinza</p>
<pre><code>
import matplotlib.pyplot as plt
import numpy as np
from skimage import data, img_as_float
from skimage.color import rgb2gray
from skimage.exposure import equalize_hist, cumulative_distribution

img = plt.imread("foto.jpg")
img_gray = rgb2gray(img)
plt.imshow(img_gray, cmap="gray")
plt.show()
</code></pre> 
<img src="images/foto_cinza.png"><br>
<p>Foto cinza</p>
<p>Limiarização</p>
<p>*Nota: a foto tem que estar em preto e branco</p>
<pre><code>
#1
#limiarização com 0.7
img_res = (img_gray > 0.7)*1
plt.imshow(img_res, cmap="gray")
plt.show()</code></pre>

<img src= "images/limear.png">
<p>foto após limiarização</p><br>
<br><br>

<pre><code>
#2
#histograma imagem cinza
plt.hist(img_gray.ravel())
plt.show()
</code></pre>
<img src= "images/Figure_1.png">
<p>Histograma da figura cinza</p><br>
<br><br>


<pre><code>
#3
#histograma imagem colorida e por canal

red = img[:,:,0]
green = img[:,:,1]
blue = img[:,:,2]

plt.hist(red.ravel(),color='red',alpha=0.4, label='Vermelho')
plt.hist(green.ravel(),color='green', alpha=0.2, label='Verde')
plt.hist(blue.ravel(),color='blue',alpha=0.5, label='Azul')
plt.legend(loc='upper right')
plt.show()
</code></pre>
<img src= "images/Figure_2.png">
<p>Histograma da figura colorida e separada por canais RGB</p><br>
<br><br>
<p>*Nota: a foto está em preto e branco</p>
<pre><code>
#4
#histograma imagem equalizado
img_eq = equalize_hist(img_gray)

plt.hist(img_eq.ravel())
plt.show()

</code></pre>
<img src= "images/Figure_3.png">
<p>Histograma da figura equalizada</p><br>
<br><br>

<p>5.</p> 
<p>para detectar se uma foto está subexposta ou sobrexposta, pode se verificar o histograma da imagem em preto e branco, se ela for subexposta o histograma estará com uma incidência maior no lado esquerdo do gráfico (valor 0), se ela for superexposta ela terá uma incidência maior no lado direito (valor 1)</p>
<p> Exemplo:</p>
<img src="images/exposure.jpg"><br>
<a href= 'https://www.designerd.com.br/wp-content/uploads/2019/09/para-que-serve-e-como-utilizar-o-histograma-na-hora-de-tirar-uma-foto-1.jpg'>foto retirada de</a>
<br><br><br>

<p>6.</p> 
<p>para detectar se uma foto está com alto contraste ou baixo contraste, pode se verificar o histograma da imagem, se ela for contrastante o gráfico parecerá um U, ou seja,haverá uma incidência maior nos cantos da imagem (0 e 1), se ela tiver pouco contraste haverá pouca incidência nos cantos do gráfico (0 e 1)</p>
<p>Exemplo:</p>
<img src="images/contraste.jpg"><br>
<a href='https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQnGfIpyoWzER1ytHBxJZTOHJTP9ieaJ84Yjg&usqp=CAU'> https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQnGfIpyoWzER1ytHBxJZTOHJTP9ieaJ84Yjg&usqp=CAU</a><br>

<br><br><br><br>
<p class = "subtitulo">Aula 10 eu acho </p>
<br>
<p>Faça uma pesquisa sobre como é possível aplicar os operadores de gradiente Roberts, Prewitt e Sobel para detectar bordas em uma imagem, usando a linguagem Python.</p>

<p>Para cada operador, inclua o trecho de código que exemplifica a operação e um conjunto de quatro imagens (para cada operação) mostrando a imagem original, a imagem resultante da operação na horizontal, a imagem resultante da operação na vertical e a imagem representando a magnitude do gradiente.</p>  

<p>Inclua as referências usadas na pesquisa.</p>
<a href='https://scikit-image.org/docs/stable/api/skimage.data.html'> imagens do skimage</a><br>
<br><br>
<p class = "subtitulo">Gradiente Roberts</p>
<p> Algoritmo de detecção de borda, sendo o mais antigo e simples, ele utiliza duas matrizes 2x2 para encontrar variações em X e Y</p>
<p> Algoritmo: |G| = raiz quadrada de((Gx^2) + (Gy^2)) </p>
<p> vantagens : </p>
<p> - Rápido </p>
<p> - Simples de implementar </p>
<br>
<p> Desvantagens: </p>
<p> - Sensível ao ruído </p>
<br>
<p>Código:</p>
<pre><code>
import cv2
import numpy as np
from scipy import ndimage
from skimage import data
import matplotlib.pyplot as plt

#matrizes
robert_X = np.array( [[1,0],[0,-1]] )
robert_Y = np.array( [[0,1],[-1,0]] )

#imagem
img = data.camera()

#algoritimo
vertical = ndimage.convolve( img, robert_X )
horizontal = ndimage.convolve( img, robert_Y )
final_img = np.sqrt( np.square(horizontal) + np.square(vertical))

#imprime as imagens
fig = plt.figure(figsize=(5, 5))
fig.add_subplot(1, 2, 1)
plt.imshow(img,cmap='gray')
plt.title('original')
fig.add_subplot(1, 2, 2)
plt.imshow(final_img,cmap='gray')
plt.title('após filtro')
plt.show()
</code></pre>
<br>
<p>Resultado</p>
<img src="images/aula_10_robert.png"><br>
<p> Como se pode observar, o gradiente é muito sensível ao ruido da imagem</p><br>
<p>referências:</p>
<a href='https://lapix.ufsc.br/metodos-no-domino-do-espaco-2-deteccao-de-bordas/'> https://lapix.ufsc.br/metodos-no-domino-do-espaco-2-deteccao-de-bordas/</a><br>
<a href='https://homepages.inf.ed.ac.uk/rbf/HIPR2/roberts.htm'> https://homepages.inf.ed.ac.uk/rbf/HIPR2/roberts.htm</a><br>
<a href='https://www.geeksforgeeks.org/python-opencv-roberts-edge-detection/'> https://www.geeksforgeeks.org/python-opencv-roberts-edge-detection/</a><br><br>
<p class = "subtitulo">Gradiente Sobel</p>
<p> Algoritimo de detecção de borda, parecido com o Roberts, ele utiliza, normalmente, 2 matrizes 3x3</p>
<p> Algoritimo: |G| = |Gx| + |Gy|</p>
<p> Vantagens: </p>
<p>- Por usar uma máscara 3x3 ele é mais preciso que o Roberts, ou seja, ele sofre menos com os ruídos na imagem</p>
<p> Desvantagens:</p>
<p>- Por utilizar uma máscara maior, ele é mais complexo</p>
<br>
<p>Código:</p>
<pre><code>
import cv2
import numpy as np
from scipy import ndimage
from skimage import data
import matplotlib.pyplot as plt

#imagem
img = data.camera()

#algoritimo
vertical = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)
horizontal = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)
final_img = cv2.addWeighted(abs(vertical), 0.5, abs(horizontal), 0.5,0)

#imprime as imagens
fig = plt.figure(figsize=(5, 5))
fig.add_subplot(1, 2, 1)
plt.imshow(img,cmap='gray')
plt.title('original')
fig.add_subplot(1, 2, 2)
plt.imshow(final_img,cmap='gray')
plt.title('após filtro')
plt.show()
</code></pre>
<br>
<p>Resultado: </p>
<img src="images/aula_10_sobel.png"><br>
<p>Como pode ver, ele sofre bem menos com ruido </p>
<p> Referências: </p>
<a href='https://lapix.ufsc.br/metodos-no-domino-do-espaco-2-deteccao-de-bordas/'> https://lapix.ufsc.br/metodos-no-domino-do-espaco-2-deteccao-de-bordas/</a><br>
<a href='https://stackoverflow.com/questions/42802352/sobel-edge-detection-in-python-and-opencv'> https://stackoverflow.com/questions/42802352/sobel-edge-detection-in-python-and-opencv</a><br>
<a href='https://www.geeksforgeeks.org/python-program-to-detect-the-edges-of-an-image-using-opencv-sobel-edge-detection/?ref=rp'> https://www.geeksforgeeks.org/python-program-to-detect-the-edges-of-an-image-using-opencv-sobel-edge-detection/?ref=rp</a><br><br>
<p class = "subtitulo">Gradiente Prewitt</p>
<p>Algoritimo de detecção de borda, parecido com o de Sobel, mas com 3 matrizes, sendo que 1 delas é rotacionada em 90 graus 3 vezes, o que faz com que seja 8 matrizes</p>
<p> Vantagens: </p>
<p>- Ainda mais preciso</p>
<p> Desvantagens:</p>
<p>- Ainda mias complxo</p>
<br>
<p>Código:</p>
<pre><code>
import cv2
import numpy as np
from scipy import ndimage
from skimage import data
import matplotlib.pyplot as plt

#imagem
img = data.camera()

#matriz
wit_x = np.array([ [1,1,1], [0,0,0], [-1,-1,-1] ])
wit_y = np.array([ [-1,0,1], [-1,0,1], [-1,0,1] ])

#algoritimo
vertical = cv2.filter2D(img, -1, wit_x)
horizontal = cv2.filter2D(img, -1, wit_y)
final_img = vertical+horizontal

#imprime as imagens
fig = plt.figure(figsize=(5, 5))
fig.add_subplot(1, 2, 1)
plt.imshow(img,cmap='gray')
plt.title('original')
fig.add_subplot(1, 2, 2)
plt.imshow(final_img,cmap='gray')
plt.title('após filtro')
plt.show()

</code></pre>
<br>
<p>Resultado: </p>
<img src="images/aula_10_prewitt.png"><br>
<p>Melhor detecção de borda</p>
<p> Referências: </p>
<a href='https://lapix.ufsc.br/metodos-no-domino-do-espaco-2-deteccao-de-bordas/'> https://lapix.ufsc.br/metodos-no-domino-do-espaco-2-deteccao-de-bordas/</a><br>
<a href='https://gist.github.com/rahit/c078cabc0a48f2570028bff397a9e154'>https://gist.github.com/rahit/c078cabc0a48f2570028bff397a9e154</a><br>

<br><br><br><br>
<p class = "subtitulo">Aula 12 </p>
<p>Faça uma pesquisa sobre APIs gráficas e elabore um resumo sobre seus achados. Para cada API gráfica (descreva pelo menos duas), inclua como a pipeline é documentada pelos desenvolvedores da API e quais linguagens de shading (shaders) são suportadas por cada API.

Mostre um exemplo de código que usa cada API gráfica (pode ser um “Hello, World!” gráfico – renderizar um triângulo na tela), um exemplo de código de shader para cada API gráfica e um exemplo de aplicação que usa cada API gráfica.</p>
<br>
<p class="subtitulo">OpenGL</p>
<p>De acordo com a wiki: "OpenGL é o nome para uma especificação que descreve o comportamento de um sistema de renderização baseado em rasteirização"</p>
<p>Por ser uma especificação ele não tem código fonte, e normalmente o vendedor de hardware que implementa as especificações e funcionalidades</p>
<p>Sobre qual linguagem podem ser utilizadas, oficialmente apenas C ou C++ estão vinculadas, mas existem outras linguagens vinculdas que não são oficiais, como Python, C#, Lua etc.</p>
<p>Pipeline:</p>
<p>Informações sobre a pipeline podem ser encontradas em:</p>
<a ref='https://www.khronos.org/opengl/wiki/Rendering_Pipeline_Overview'>khronos.org</a>
<img src="images/OpenGL.png"><br>
<a ref="https://www.khronos.org/opengl/wiki/Rendering_Pipeline_Overview">imagem pega de</a>
<br>
</body>
</html>
