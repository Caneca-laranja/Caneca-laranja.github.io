<!DOCTYPE html>
<html>
<head> 
<link rel = "stylesheet" href="index_style.css">
<link rel = "stylesheet" href="images">
<link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
</head>
<body>

<p class="titulo">Computação visual</p>
<br><br>
<p class="subtitulo">Aula 1:</p>
<p class="subtitulo">O que eu achava que era:</p>

<p>
1. Programar GUIs, UX (User experience) e design de sites e softwares em geral.<br>
2. Modelação 3D e 2D. 
</p>

<br><br>

<p class="subtitulo">Exemplos de sub-área</p>

<p class="subsubtitulo">Computação Gráfica </p>
<p> 
Exemplo: Shading utilizando OpenGL<br>
Site: https://learnopengl.com/Getting-started/Shaders<br>
Descrição: É um tutorial sobre como funciona o OpenGL, ele inclui exemplos, explicação, código
fonte para auxiliar, exercícios com resposta e a documentação é bem escrita.<br>
Motivo: Realmente é bem feito esse tutorial, e como é feito em C++ eu também tenho familiaridade,
além de ser bem simples.
</p>


<p class="subsubtitulo">Visão Computacional</p>
<p>
Exemplo: Detecção de digital utilizando Edge Detection<br>
Site: https://chooch.ai/computer-vision/what-are-the-applications-of-edge-detection/#:~:text=Applying%20edge%20detection%20makes%20it,cases%3A%20self%2Ddriving%20cars.<br>
Site2: https://d1wqtxts1xzle7.cloudfront.net/68544602/0031-3203_2887_2990078-120210803-2319-15ky6jc.pdf?1627992344=&response-content-disposition=inline%3B+filename%3DEdge_Detection_in_fingerprints.pdf&Expires=1645033301&Signature=I5uaw~tdtV5X~W4fs96CH8DEqy7OJaZQEJPk-mGBc4~QDiNmbOBaU0W5hDnYnknEr9vAYu3xhHQszNWsqF7IWirdRvRSJqBmmYE1SEiQi0xpzagNJgpca0G-oplXCC4EfUuG-FcI6rh2~ICkcN57mX5whYRDYSgzel36w3WySNkz6EjKULGqhl3CZUgk8JzlMUDbAndjX~ifw-wzVkh5GNdta6Ry7MYN9ZVRPVy2Rw-CbrsNg8hkDav~eS40v4Aq1hZ9Ry1gpIc2qoRbDNlYUEkves4jJLQkhOvWB5NwHsdFLYHEQO91caJxVmSvRWaltWZ-ZwJS9eM6dO3nDH62dA__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA<br><br>
Descrição: Utilizando Edge detection para verificar o contorno da digital em contraste com o fundo, e diminuir o ruído causado.<br>
Motivo: É uma tecnologia usada atualmente em vários sistemas, como bancos para verificar a autenticidade da pessoa.<br>
</p>

<p class="subsubtitulo">Processamento de Imagens</p> 
<p>
Exemplo: Transmissão e codificação de imagens.<br>
Site: https://www.tutorialspoint.com/dip/applications_and_usage.htm<br>
Descrição: Codificação e transmissão de imagens e vídeos, com mais rapidez e melhoria nas imagens, permitindo até transmissão ao vivo (LIVE) <br>
Motivo:Parecia interessante, também é utilizado bastante hoje em dia, principalmente por conta da pandemia. 
</p>


<br><br><br><br>
<p class = "subtitulo">Aula 2 </p>
<br>
<p> Problema: Identificação Automática de placas de veículo</p><br>
<p> Solução: Utilizando Python, OpenCV, biblioteca pytesseract e Raspberry PI para detectar as letras da placa</p>
<p>Como o filtro ajudou: Foi utilizado o Blur gaussaniano para melhorar a imagem</p>
<p> site/ papel: https://professor.luzerna.ifc.edu.br/ricardo-antonello/wp-content/uploads/sites/8/2016/04/IDENTIFICA%c3%87%c3%83O-AUTOM%c3%81TICA-DE-PLACA-DE-VE%c3%8dCULOS-ATRAV%c3%89S-DE-PROCESSAMENTO-DE-IMAGEM-E-VIS%c3%83O-COMPUTACIONAL-.pdf</p>
<p> Importante: No papel se encontra, o código usado e exemplos utilizando placas</p>
<img src = "tela_placa_carro.png" >
<p>Imagem pega de https://professor.luzerna.ifc.edu.br/ricardo-antonello/wp-content/uploads/sites/8/2016/04/IDENTIFICA%c3%87%c3%83O-AUTOM%c3%81TICA-DE-PLACA-DE-VE%c3%8dCULOS-ATRAV%c3%89S-DE-PROCESSAMENTO-DE-IMAGEM-E-VIS%c3%83O-COMPUTACIONAL-.pdf</p>
<br><br><br><br>

<p class = "subtitulo">Aula 6, eu acho </p>
<p>Com base no material disponível no Moodle (slides sobre “Transformações de Intensidade e Filtragem Espacial”, em particular, os tópico de transformação de intensidade e de processamento de histograma – slides 13 a 57) e referências adicionais, faça uma pesquisa sobre como é possível: </p>

<p>1.Realizar a limiarização de uma imagem usando Python e scikit-image.</p>
<p>2.Plotar o histograma de uma imagem tons de cinza usando Python, scikit-image e matplotlib.</p>
<p>3.Plotar o histograma de uma imagem colorida (um histograma por canal de cor) usando Python, scikit-image e matplotlib.</p>
<p>4.Equalizar o histograma de uma imagem usando Python e scikit-image.</p>
<p>5.Detectar (concluir) que uma foto está subexposta ou que está superexposta, analisando o histograma.</p>
<p>6.Detectar (concluir) se uma imagem está com baixo contraste ou alto contraste, analisando o histograma.</p>
<p>Para cada item acima, inclua um código que exemplifica cada tarefa e uma imagem resultante do código (por exemplo, no item 2, a imagem deve conter a imagem em tons de cinza e o histograma da imagem).</p>

<p>Inclua as referências usadas na pesquisa.</p>
<p> referências:</p>
<a href='https://images.aws.nestle.recipes/resized/40b25559b85b265e885f55ec7c1e4d04_torta-lim%C3%A3o-receitas-nestle_1200_600.jpg'>Imagem</a><br>
<a href='https://www.kaggle.com/code/sanikamal/image-processing-with-scikit-image/notebook'>https://www.kaggle.com/code/sanikamal/image-processing-with-scikit-image/notebook</a><br>
<a href='https://scikit-image.org/docs/stable/auto_examples/color_exposure/plot_local_equalize.html'>https://scikit-image.org/docs/stable/auto_examples/color_exposure/plot_local_equalize.html</a><br>
<a href='https://acervolima.com/segmentacao-de-imagens-usando-o-modulo-scikit-image-do-python/'>https://acervolima.com/segmentacao-de-imagens-usando-o-modulo-scikit-image-do-python/</a><br>
<a href='https://www.tecmundo.com.br/internet/8616-fotografia-como-funcionam-os-histogramas.htm'>https://www.tecmundo.com.br/internet/8616-fotografia-como-funcionam-os-histogramas.htm</a><br>
<br><br>
<img src= "images/foto.jpg"><br>
<p>Foto original</p>

<p>código para foto cinza</p>
<pre><code>
import matplotlib.pyplot as plt
import numpy as np
from skimage import data, img_as_float
from skimage.color import rgb2gray
from skimage.exposure import equalize_hist, cumulative_distribution

img = plt.imread("foto.jpg")
img_gray = rgb2gray(img)
plt.imshow(img_gray, cmap="gray")
plt.show()
</code></pre> 
<img src="images/foto_cinza.png"><br>
<p>Foto cinza</p>
<p>Limiarização</p>
<p>*Nota: a foto tem que estar em preto e branco</p>
<pre><code>
#1
#limiarização com 0.7
img_res = (img_gray > 0.7)*1
plt.imshow(img_res, cmap="gray")
plt.show()</code></pre>

<img src= "images/limear.png">
<p>foto após limiarização</p><br>
<br><br>

<pre><code>
#2
#histograma imagem cinza
plt.hist(img_gray.ravel())
plt.show()
</code></pre>
<img src= "images/Figure_1.png">
<p>Histograma da figura cinza</p><br>
<br><br>


<pre><code>
#3
#histograma imagem colorida e por canal

red = img[:,:,0]
green = img[:,:,1]
blue = img[:,:,2]

plt.hist(red.ravel(),color='red',alpha=0.4, label='Vermelho')
plt.hist(green.ravel(),color='green', alpha=0.2, label='Verde')
plt.hist(blue.ravel(),color='blue',alpha=0.5, label='Azul')
plt.legend(loc='upper right')
plt.show()
</code></pre>
<img src= "images/Figure_2.png">
<p>Histograma da figura colorida e separada por canais RGB</p><br>
<br><br>
<p>*Nota: a foto está em preto e branco</p>
<pre><code>
#4
#histograma imagem equalizado
img_eq = equalize_hist(img_gray)

plt.hist(img_eq.ravel())
plt.show()

</code></pre>
<img src= "images/Figure_3.png">
<p>Histograma da figura equalizada</p><br>
<br><br>

<p>5.</p> 
<p>para detectar se uma foto está subexposta ou sobrexposta, pode se verificar o histograma da imagem em preto e branco, se ela for subexposta o histograma estará com uma incidência maior no lado esquerdo do gráfico (valor 0), se ela for superexposta ela terá uma incidência maior no lado direito (valor 1)</p>
<p> Exemplo:</p>
<img src="images/exposure.jpg"><br>
<a href= 'https://www.designerd.com.br/wp-content/uploads/2019/09/para-que-serve-e-como-utilizar-o-histograma-na-hora-de-tirar-uma-foto-1.jpg'>foto retirada de</a>
<br><br><br>

<p>6.</p> 
<p>para detectar se uma foto está com alto contraste ou baixo contraste, pode se verificar o histograma da imagem, se ela for contrastante o gráfico parecerá um U, ou seja,haverá uma incidência maior nos cantos da imagem (0 e 1), se ela tiver pouco contraste haverá pouca incidência nos cantos do gráfico (0 e 1)</p>
<p>Exemplo:</p>
<img src="images/contraste.jpg"><br>
<a href='https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQnGfIpyoWzER1ytHBxJZTOHJTP9ieaJ84Yjg&usqp=CAU'> https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQnGfIpyoWzER1ytHBxJZTOHJTP9ieaJ84Yjg&usqp=CAU</a><br>

<br><br><br><br>
<p class = "subtitulo">Aula 10 eu acho </p>
<br>
<p>Faça uma pesquisa sobre como é possível aplicar os operadores de gradiente Roberts, Prewitt e Sobel para detectar bordas em uma imagem, usando a linguagem Python.</p>

<p>Para cada operador, inclua o trecho de código que exemplifica a operação e um conjunto de quatro imagens (para cada operação) mostrando a imagem original, a imagem resultante da operação na horizontal, a imagem resultante da operação na vertical e a imagem representando a magnitude do gradiente.</p>  

<p>Inclua as referências usadas na pesquisa.</p>
<a href='https://scikit-image.org/docs/stable/api/skimage.data.html'> imagens do skimage</a><br>
<br><br>
<p class = "subtitulo">Gradiente Roberts</p>
<p> Algoritmo de detecção de borda, sendo o mais antigo e simples, ele utiliza duas matrizes 2x2 para encontrar variações em X e Y</p>
<p> Algoritmo: |G| = raiz quadrada de((Gx^2) + (Gy^2)) </p>
<p> vantagens : </p>
<p> - Rápido </p>
<p> - Simples de implementar </p>
<br>
<p> Desvantagens: </p>
<p> - Sensível ao ruído </p>
<br>
<p>Código:</p>
<pre><code>
import cv2
import numpy as np
from scipy import ndimage
from skimage import data
import matplotlib.pyplot as plt

#matrizes
robert_X = np.array( [[1,0],[0,-1]] )
robert_Y = np.array( [[0,1],[-1,0]] )

#imagem
img = data.camera()

#algoritimo
vertical = ndimage.convolve( img, robert_X )
horizontal = ndimage.convolve( img, robert_Y )
final_img = np.sqrt( np.square(horizontal) + np.square(vertical))

#imprime as imagens
fig = plt.figure(figsize=(5, 5))
fig.add_subplot(1, 2, 1)
plt.imshow(img,cmap='gray')
plt.title('original')
fig.add_subplot(1, 2, 2)
plt.imshow(final_img,cmap='gray')
plt.title('após filtro')
plt.show()
</code></pre>
<br>
<p>Resultado</p>
<img src="images/aula_10_robert.png"><br>
<p> Como se pode observar, o gradiente é muito sensível ao ruido da imagem</p><br>
<p>referências:</p>
<a href='https://lapix.ufsc.br/metodos-no-domino-do-espaco-2-deteccao-de-bordas/'> https://lapix.ufsc.br/metodos-no-domino-do-espaco-2-deteccao-de-bordas/</a><br>
<a href='https://homepages.inf.ed.ac.uk/rbf/HIPR2/roberts.htm'> https://homepages.inf.ed.ac.uk/rbf/HIPR2/roberts.htm</a><br>
<a href='https://www.geeksforgeeks.org/python-opencv-roberts-edge-detection/'> https://www.geeksforgeeks.org/python-opencv-roberts-edge-detection/</a><br><br>
<p class = "subtitulo">Gradiente Sobel</p>
<p> Algoritimo de detecção de borda, parecido com o Roberts, ele utiliza, normalmente, 2 matrizes 3x3</p>
<p> Algoritimo: |G| = |Gx| + |Gy|</p>
<p> Vantagens: </p>
<p>- Por usar uma máscara 3x3 ele é mais preciso que o Roberts, ou seja, ele sofre menos com os ruídos na imagem</p>
<p> Desvantagens:</p>
<p>- Por utilizar uma máscara maior, ele é mais complexo</p>
<br>
<p>Código:</p>
<pre><code>
import cv2
import numpy as np
from scipy import ndimage
from skimage import data
import matplotlib.pyplot as plt

#imagem
img = data.camera()

#algoritimo
vertical = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)
horizontal = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)
final_img = cv2.addWeighted(abs(vertical), 0.5, abs(horizontal), 0.5,0)

#imprime as imagens
fig = plt.figure(figsize=(5, 5))
fig.add_subplot(1, 2, 1)
plt.imshow(img,cmap='gray')
plt.title('original')
fig.add_subplot(1, 2, 2)
plt.imshow(final_img,cmap='gray')
plt.title('após filtro')
plt.show()
</code></pre>
<br>
<p>Resultado: </p>
<img src="images/aula_10_sobel.png"><br>
<p>Como pode ver, ele sofre bem menos com ruido </p>
<p> Referências: </p>
<a href='https://lapix.ufsc.br/metodos-no-domino-do-espaco-2-deteccao-de-bordas/'> https://lapix.ufsc.br/metodos-no-domino-do-espaco-2-deteccao-de-bordas/</a><br>
<a href='https://stackoverflow.com/questions/42802352/sobel-edge-detection-in-python-and-opencv'> https://stackoverflow.com/questions/42802352/sobel-edge-detection-in-python-and-opencv</a><br>
<a href='https://www.geeksforgeeks.org/python-program-to-detect-the-edges-of-an-image-using-opencv-sobel-edge-detection/?ref=rp'> https://www.geeksforgeeks.org/python-program-to-detect-the-edges-of-an-image-using-opencv-sobel-edge-detection/?ref=rp</a><br><br>
<p class = "subtitulo">Gradiente Prewitt</p>
<p>Algoritimo de detecção de borda, parecido com o de Sobel, mas com 3 matrizes, sendo que 1 delas é rotacionada em 90 graus 3 vezes, o que faz com que seja 8 matrizes</p>
<p> Vantagens: </p>
<p>- Ainda mais preciso</p>
<p> Desvantagens:</p>
<p>- Ainda mias complxo</p>
<br>
<p>Código:</p>
<pre><code>
import cv2
import numpy as np
from scipy import ndimage
from skimage import data
import matplotlib.pyplot as plt

#imagem
img = data.camera()

#matriz
wit_x = np.array([ [1,1,1], [0,0,0], [-1,-1,-1] ])
wit_y = np.array([ [-1,0,1], [-1,0,1], [-1,0,1] ])

#algoritimo
vertical = cv2.filter2D(img, -1, wit_x)
horizontal = cv2.filter2D(img, -1, wit_y)
final_img = vertical+horizontal

#imprime as imagens
fig = plt.figure(figsize=(5, 5))
fig.add_subplot(1, 2, 1)
plt.imshow(img,cmap='gray')
plt.title('original')
fig.add_subplot(1, 2, 2)
plt.imshow(final_img,cmap='gray')
plt.title('após filtro')
plt.show()

</code></pre>
<br>
<p>Resultado: </p>
<img src="images/aula_10_prewitt.png"><br>
<p>Melhor detecção de borda</p>
<p> Referências: </p>
<a href='https://lapix.ufsc.br/metodos-no-domino-do-espaco-2-deteccao-de-bordas/'> https://lapix.ufsc.br/metodos-no-domino-do-espaco-2-deteccao-de-bordas/</a><br>
<a href='https://gist.github.com/rahit/c078cabc0a48f2570028bff397a9e154'>https://gist.github.com/rahit/c078cabc0a48f2570028bff397a9e154</a><br>

<br><br><br><br>
<p class = "subtitulo">Aula 12 </p>
<p>Faça uma pesquisa sobre APIs gráficas e elabore um resumo sobre seus achados. Para cada API gráfica (descreva pelo menos duas), inclua como a pipeline é documentada pelos desenvolvedores da API e quais linguagens de shading (shaders) são suportadas por cada API.

Mostre um exemplo de código que usa cada API gráfica (pode ser um “Hello, World!” gráfico – renderizar um triângulo na tela), um exemplo de código de shader para cada API gráfica e um exemplo de aplicação que usa cada API gráfica.</p>
<br>
<p>Nota: não connsegui utilizar a biblioteca GLFW/glfw3.h e como ela é necessária para ambos as APIs utilizadas o código foi pego do site, mas não consegui executar</p>
<br>
<p class="subtitulo">OpenGL</p>
<p>De acordo com a wiki: "OpenGL é o nome para uma especificação que descreve o comportamento de um sistema de renderização baseado em rasteirização"</p>
<p>Por ser uma especificação ele não tem código fonte, e normalmente o vendedor de hardware que implementa as especificações e funcionalidades</p>
<p>Sobre qual linguagem podem ser utilizadas, oficialmente apenas C ou C++ estão vinculadas, mas existem outras linguagens vinculdas que não são oficiais, como Python, C#, Lua etc.</p>
<p>Pipeline:</p>
<p>Informações sobre a pipeline podem ser encontradas em:</p>
<a href='https://www.khronos.org/opengl/wiki/Rendering_Pipeline_Overview'>https://www.khronos.org/opengl/wiki/Rendering_Pipeline_Overview</a>
<img src="images/OpenGL.png"><br>
<a href="https://www.khronos.org/opengl/wiki/Rendering_Pipeline_Overview">https://www.khronos.org/opengl/wiki/Rendering_Pipeline_Overview</a>
<br>
<pre><code = "language-pascal">

// CPP program to render a triangle using Shaders
#include GL\freeglut.h
#include GL\glew.h
#include iostream
#include string

std::string vertexShader = "#version 430\n"
						"in vec3 pos;"
						"void main() {"
						"gl_Position = vec4(pos, 1);"
						"}";

std::string fragmentShader = "#version 430\n"
							"void main() {"
							"gl_FragColor = vec4(1, 0, 0, 1);"
							"}";

// Compile and create shader object and returns its id
GLuint compileShaders(std::string shader, GLenum type)
{

	const char* shaderCode = shader.c_str();
	GLuint shaderId = glCreateShader(type);

	if (shaderId == 0) { // Error: Cannot create shader object
		std::cout  "Error creating shaders";
		return 0;
	}

	// Attach source code to this object
	glShaderSource(shaderId, 1, &shaderCode, NULL);
	glCompileShader(shaderId); // compile the shader object

	GLint compileStatus;

	// check for compilation status
	glGetShaderiv(shaderId, GL_COMPILE_STATUS, &compileStatus);

	if (!compileStatus) { // If compilation was not successful
		int length;
		glGetShaderiv(shaderId, GL_INFO_LOG_LENGTH, &length);
		char* cMessage = new char[length];

		// Get additional information
		glGetShaderInfoLog(shaderId, length, &length, cMessage);
		std::cout "Cannot Compile Shader: "  cMessage;
		delete[] cMessage;
		glDeleteShader(shaderId);
		return 0;
	}

	return shaderId;
}

// Creates a program containing vertex and fragment shader
// links it and returns its ID
GLuint linkProgram(GLuint vertexShaderId, GLuint fragmentShaderId)
{
	GLuint programId = glCreateProgram(); // create a program

	if (programId == 0) {
		std::cout "Error Creating Shader Program";
		return 0;
	}

	// Attach both the shaders to it
	glAttachShader(programId, vertexShaderId);
	glAttachShader(programId, fragmentShaderId);

	// Create executable of this program
	glLinkProgram(programId);

	GLint linkStatus;

	// Get the link status for this program
	glGetProgramiv(programId, GL_LINK_STATUS, &linkStatus);

	if (!linkStatus) { // If the linking failed
		std::cout "Error Linking program";
		glDetachShader(programId, vertexShaderId);
		glDetachShader(programId, fragmentShaderId);
		glDeleteProgram(programId);

		return 0;
	}

	return programId;
}

// Load data in VBO and return the vbo's id
GLuint loadDataInBuffers()
{
	GLfloat vertices[] = { // vertex coordinates
						-0.7, -0.7, 0,
						0.7, -0.7, 0,
						0, 0.7, 0
	};

	GLuint vboId;

	// allocate buffer space and pass data to it
	glGenBuffers(1, &vboId);
	glBindBuffer(GL_ARRAY_BUFFER, vboId);
	glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);

	// unbind the active buffer
	glBindBuffer(GL_ARRAY_BUFFER, 0);

	return vboId;
}

// Initialize and put everything together
void init()
{
	// clear the framebuffer each frame with black color
	glClearColor(0, 0, 0, 0);

	GLuint vboId = loadDataInBuffers();

	GLuint vShaderId = compileShaders(vertexShader, GL_VERTEX_SHADER);
	GLuint fShaderId = compileShaders(fragmentShader, GL_FRAGMENT_SHADER);

	GLuint programId = linkProgram(vShaderId, fShaderId);

	// Get the 'pos' variable location inside this program
	GLuint posAttributePosition = glGetAttribLocation(programId, "pos");

	GLuint vaoId;
	glGenVertexArrays(1, &vaoId); // Generate VAO

	// Bind it so that rest of vao operations affect this vao
	glBindVertexArray(vaoId);

	// buffer from which 'pos' will receive its data and the format of that data
	glBindBuffer(GL_ARRAY_BUFFER, vboId);
	glVertexAttribPointer(posAttributePosition, 3, GL_FLOAT, false, 0, 0);

	// Enable this attribute array linked to 'pos'
	glEnableVertexAttribArray(posAttributePosition);

	// Use this program for rendering.
	glUseProgram(programId);
}

// Function that does the drawing
// glut calls this function whenever it needs to redraw
void display()
{
	// clear the color buffer before each drawing
	glClear(GL_COLOR_BUFFER_BIT);

	// draw triangles starting from index 0 and
	// using 3 indices
	glDrawArrays(GL_TRIANGLES, 0, 3);

	// swap the buffers and hence show the buffers
	// content to the screen
	glutSwapBuffers();
}

// main function
// sets up window to which we'll draw
int main(int argc, char** argv)
{
	glutInit(&argc, argv);
	glutInitDisplayMode(GLUT_RGB | GLUT_DOUBLE);
	glutInitWindowSize(500, 500);
	glutInitWindowPosition(100, 50);
	glutCreateWindow("Triangle Using OpenGL");
	glewInit();
	init();
	glutDisplayFunc(display);
	glutMainLoop();
	return 0;
}

</pre></code>
<a href='https://www.geeksforgeeks.org/rendering-triangle-using-openglusing-shaders/'>https://www.geeksforgeeks.org/rendering-triangle-using-openglusing-shaders/</a>
<p>Nota: devido a conflitos com "<>", ele foi retirado no código </p>
<br><br>
<p class='subtitulo'>Vulkan</p>
<p>De acordo com a wiki, Vulkan é "C99 API criado para controle explícito para gráficos de baixo nível e funcionalidade computacional".</p>
<p>Nota: C99 é uma versão da liguagem C/C++</p>
<p>Pipeline:</p>
<img src="images/Vulkan.png">
<a href="https://www.khronos.org/registry/vulkan/specs/1.3-extensions/html/chap10.html">https://www.khronos.org/registry/vulkan/specs/1.3-extensions/html/chap10.html</a>
<br>
<pre><code>
#define GLFW_INCLUDE_VULKAN
#include GLFW/glfw3.h

#include iostream
#include stdexcept
#include cstdlib

const uint32_t WIDTH = 800;
const uint32_t HEIGHT = 600;

class HelloTriangleApplication {
public:
    void run() {
        initWindow();
        initVulkan();
        mainLoop();
        cleanup();
    }

private:
    GLFWwindow* window;

    void initWindow() {
        glfwInit();

        glfwWindowHint(GLFW_CLIENT_API, GLFW_NO_API);
        glfwWindowHint(GLFW_RESIZABLE, GLFW_FALSE);

        window = glfwCreateWindow(WIDTH, HEIGHT, "Vulkan", nullptr, nullptr);
    }

    void initVulkan() {

    }

    void mainLoop() {
        while (!glfwWindowShouldClose(window)) {
            glfwPollEvents();
        }
    }

    void cleanup() {
        glfwDestroyWindow(window);

        glfwTerminate();
    }
};

int main() {
    HelloTriangleApplication app;

    try {
        app.run();
    } catch (const std::exception& e) {
        std::cerr  e.what()  std::endl;
        return EXIT_FAILURE;
    }

    return EXIT_SUCCESS;
}
</code></pre>
<p>Nota: devido a conflitos com "<>", ele foi retirado no código </p>
<a href="https://vulkan-tutorial.com/code/00_base_code.cpp">https://vulkan-tutorial.com/code/00_base_code.cpp</a>
<br><br><br><br>
<p class="subtitulo">Aula ???:</p>
<p>Toon/Cel shading</p>
<p>Faça uma pesquisa sobre a técnica de toon/cel shading e escreva um resumo sobre como essa técnica funciona.

	Além da descrição da técnica, inclua em seu resumo:
	
	Quais são as semelhanças e diferenças entre o toon/cel shading e o Gouraud e Phong shading?
	Inclua imagens que mostrem modelos 3D renderizados usando toon/cel shading.
	Inclua imagens que comparem o toon/cel shading com Gouraud/Phong shading.
	Inclua as referências usadas na pesquisa.</p>

<p>O Toon shading é um shading que renderiza as cores de forma a ficarem delineadas e afiadas como se fossem um cartum</p>
<p>O Toon shading é composto por 3 components principais:</p>
<p>1.o shading difuso é representado por 2 valores um para brilho e outro para escuro</p>
<p>2.Highlights são representados por uma únic cor alta</p>
<p>3.Objetos tem que ter uma silhueta</p>
<br>
<p>A diferença principal entre o Toon e o Gouraud é que um tenta ser menos realista enquanto o outro tenta ser mais.</p>
<br>
<img src="images/astronauta.jpg"/>
<p>imagem pega de: data:image/jpeg;base64,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</p>
<br>
<img src="images/transferir.jfif"/>
<p>imagem pega de: https://www.google.com/url?sa=i&url=https%3A%2F%2Fsubscription.packtpub.com%2Fbook%2Fgraphics-programming%2F9781847195722%2F7%2Fch07lvl1sec09%2Fsummary&psig=AOvVaw28uhVWi30pD_qkqZErUPI4&ust=1652822832565000&source=images&cd=vfe&ved=0CAwQjRxqFwoTCPj2sIP75PcCFQAAAAAdAAAAABAQ</p>
<br><br><br><br>
<p class="title">Aula 15</p>
<p>Nessa semana, foi apresentada a seguinte pergunta durante a aula:

	Por que obtemos resultados diferentes nas operações tex1 * tex2 e mul(tex1, tex2), considerando que tex1 e tex2 são duas texturas e que mul() é uma função da linguagem de shader HLSL?
	
	Faça uma pesquisa sobre as diferenças das duas operações e responda à pergunta acima.
	
	Inclua as referências usadas na pesquisa.
	
	Publique o resultado dessa atividade no seu blog e envie um arquivo txt contendo o link do seu blog com a publicação dessa atividade.</p>
<br>
<p>Resposta: </p>
<p>A diferença parece ser que Tx1 * Tx2, multiplica os valores de Tx2 de cada linha e coluna pelo valor de linha e coluna de Tx1.</p>
<p>Ex:</p>
<p>Tx1 = [[1,1,1],[1,1,1],[0,0,1]]</p>
<p>Tx2 = [[2,3,4]]</p>
<p>Ficará: Tx3 = Tx1 * Tx2  => Tx3 = [[2,3,4],[2,3,4],[0,0,4]]</p>
<p>Enquanto isso a função mul parece fazer a multiplicação matricial corretamente.</p>
<p>Ex:</p>
<p>Tx1 = [[1,1,1],[1,1,1],[0,0,1]]</p>
<p>Tx2 = [[2,3,4]]</p>
<p>Ficará: Tx3 = mul(Tx1,Tx2)  => Tx3 = [[5,5,9]]</p>
<br><br><br>
</body>
</html>
